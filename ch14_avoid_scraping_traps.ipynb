{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch14_avoid_scraping_traps.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lblogan14/web_scraping_with_python/blob/master/ch14_avoid_scraping_traps.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFLjdyJOFcvQ",
        "colab_type": "text"
      },
      "source": [
        "#Looking Like a Human"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LT5SCLazFl1y",
        "colab_type": "text"
      },
      "source": [
        "##Adjust Your Headers\n",
        "The *Requests* library is excellent for setting headers. HTTP headers are lists of attributes, or preferences, sent by users every time the users make a request to a web server. \\\\ \n",
        "The following seven fields are used by most major browsers when initiating any connection, for example:\n",
        "* `Host`: `https://www.google.com/`\n",
        "* `Connection`: `keep-alive`\n",
        "* `Accept`:  `text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8`\n",
        "* `User-Agent`: `Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36`\n",
        "* `Referrer`: `https://www.google.com/`\n",
        "* `Accept-Encoding`: `gzip, deflate, sdch`\n",
        "* `Accept-Language`: `en-US,en;q=0.8`\n",
        "\n",
        "The headers that a typical Python scraper using the default `urllib` library:\n",
        "* `Accept-Encoding`: `identity`\n",
        "* `User-Agent`: `Python-urllib/3.4`\n",
        "\n",
        "Headers can be completely customized using the *Requests* library. Here the example website is *https://www.whatismybrowser.com*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4__e4EjOhPS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCMMfk-POrqH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "session = requests.Session()\n",
        "headers = {'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_5)AppleWebKit 537.36 (KHTML, like Gecko) Chrome',\n",
        "           'Accept':'text/html,application/xhtml+xml,application/xml; q=0.9,image/webp,*/*;q=0.8'}\n",
        "url = 'https://www.whatismybrowser.com/developers/what-http-headers-is-my-browser-sending'\n",
        "req = session.get(url, headers=headers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVjxVQRlPBDb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "9cded60b-65fc-431a-eeaf-be523639ed48"
      },
      "source": [
        "bs = BeautifulSoup(req.text, 'html.parser')\n",
        "print(bs.find('table', {'class': 'table-striped'}).get_text)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method Tag.get_text of <table class=\"table table-striped\">\n",
            "<tr>\n",
            "<th>ACCEPT</th>\n",
            "<td>text/html,application/xhtml+xml,application/xml; q=0.9,image/webp,*/*;q=0.8</td>\n",
            "</tr>\n",
            "<tr>\n",
            "<th>ACCEPT_ENCODING</th>\n",
            "<td>gzip, deflate</td>\n",
            "</tr>\n",
            "<tr>\n",
            "<th>CONNECTION</th>\n",
            "<td>keep-alive</td>\n",
            "</tr>\n",
            "<tr>\n",
            "<th>HOST</th>\n",
            "<td>www.whatismybrowser.com</td>\n",
            "</tr>\n",
            "<tr>\n",
            "<th>USER_AGENT</th>\n",
            "<td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_5)AppleWebKit 537.36 (KHTML, like Gecko) Chrome</td>\n",
            "</tr>\n",
            "</table>>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeNmFf5APObR",
        "colab_type": "text"
      },
      "source": [
        "The output should show that the headers are now the same ones set in the headers\n",
        "dictionary object in the code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_8CKtxjFoyb",
        "colab_type": "text"
      },
      "source": [
        "##Handling Cookies with JavaScript\n",
        "Handling cookies correctly can alleviate many scraping problems, although cookies can also be a double-edged sword. Websites that track your progression through a site using cookies might attempt to cut off scrapers that display abnormal behavior, such as completing forms too quickly, or visiting too many pages. Although these behaviors can be disguised by closing and reopening connections to the site, or even changing the IP address, if the cookie gives the identity away, the user's effort of disguise might be futile. \n",
        "As mentioned in Chapter 10, cookies can be necessary to scrape a site to stay looged in on a site to be able to hold and present a cookie from page to page.\n",
        "\n",
        "If scraping a single targeted website or a small number of targeted sites, make sure to examine the cookies generated by those sites and consider which ones the scraper can handle. Some browser plug-ins can show this. For example, *EditThisCookie* is a Chrome extension that can do this.\n",
        "\n",
        "To handle cookies using the *Requests* library, go back to Chapter 10. Since *Requests* library cannot execute JavaScript, it cannot handle cookies produced by modern tracking software, such as Google Analytics. In this case, use the Selenium and PhantomJS packages.\n",
        "\n",
        "To view cookies on a site:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXVHkZ9tY7eq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from selenium import webdriver\n",
        "driver = webdriver.PhantomJS(executable_path='<Path to Phantom JS>')\n",
        "driver.get('http://pythonscraping.com')\n",
        "driver.implicitly_wait(1)\n",
        "print(driver.get_cookies())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Qwzq1TUZRz6",
        "colab_type": "text"
      },
      "source": [
        "To run this on Chrome:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMECt_AqZUCq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "\n",
        "chrome_options = Options()\n",
        "chrome_options.add_argument(\"--headless\")\n",
        "driver = webdriver.Chrome(executable_path='drivers/chromedriver', \n",
        "                          chrome_options=chrome_options)\n",
        "driver.get('http://pythonscraping.com')\n",
        "driver.implicitly_wait(1)\n",
        "print(driver.get_cookies())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XVwXhmhZb9D",
        "colab_type": "text"
      },
      "source": [
        "TO manipulate cookies, use `delete_cookie()`, `add_cookie()`, and `delete_all_cookies()` functions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jXs42dDZq7F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from selenium import webdriver"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOuO_eyzZv1l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "phantomPath = '<Path to Phantom JS>'\n",
        "\n",
        "driver = webdriver.PhantomJS(executable_path=phantomPath)\n",
        "driver.get('http://pythonscraping.com')\n",
        "driver.implicitly_wait(1)\n",
        "\n",
        "savedCookies = driver.get_cookies()\n",
        "print(savedCookies)\n",
        "\n",
        "driver2 = webdriver.PhantomJS(executable_path=phantomPath)\n",
        "driver2.get('http://pythonscraping.com')\n",
        "driver2.delete_all_cookies()\n",
        "for cookie in savedCookies:\n",
        "  if not cookie['domain'].startswith('.'):\n",
        "    cookie['domain'] = '.{}'.format(cookie['domain'])\n",
        "  driver2.add_cookie(cookie)\n",
        "  \n",
        "driver2.get('http://pythonscraping.com')\n",
        "driver.implicitly_wait(1)\n",
        "print(driver2.get_cookies())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xI3j83Wav_N",
        "colab_type": "text"
      },
      "source": [
        "The first webdriver retrieves a website, prints the cookies, and then stores them in the variable `savedCookies`. The second webdriver loads the same website, deletes its own cookies, and adds the cookies from the first webdriver."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQudqj-pbDgp",
        "colab_type": "text"
      },
      "source": [
        "To run it on Chrome:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujFXlFpqbFIu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "\n",
        "chrome_options = Options()\n",
        "chrome_options.add_argument(\"--headless\")\n",
        "\n",
        "driver = webdriver.Chrome(executable_path='drivers/chromedriver', \n",
        "                          chrome_options=chrome_options)\n",
        "driver.get('http://pythonscraping.com')\n",
        "driver.implicitly_wait(1)\n",
        "\n",
        "savedCookies = driver.get_cookies()\n",
        "print(savedCookies)\n",
        "\n",
        "driver2 = webdriver.Chrome(executable_path='drivers/chromedriver',\n",
        "                           chrome_options=chrome_options)\n",
        "\n",
        "driver2.get('http://pythonscraping.com')\n",
        "driver2.delete_all_cookies()\n",
        "for cookie in savedCookies:\n",
        "  driver2.add_cookie(cookie)\n",
        "\n",
        "driver2.get('http://pythonscraping.com')\n",
        "driver.implicitly_wait(1)\n",
        "print(driver2.get_cookies())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxHFgrvrFrnZ",
        "colab_type": "text"
      },
      "source": [
        "##Timing Is Everything\n",
        "Some well-protected websites might prevent users from submitting forms or interacting with the site if users do it too quickly. Thus, if possible, try to space the scrapers out by a few seconds, even if this means to add the following extra:\n",
        "\n",
        "\n",
        "```\n",
        "import time\n",
        "\n",
        "time.sleep(3)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vhHqNchFtQl",
        "colab_type": "text"
      },
      "source": [
        "#Common Form Security Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlKGvhS1FwDT",
        "colab_type": "text"
      },
      "source": [
        "##Hidden Input Field Values\n",
        "“Hidden” fields in HTML forms allow the value contained in the field to be viewable\n",
        "by the browser but invisible to the users (unless they look at the site’s source code).\n",
        "\n",
        "Hidden fields are used to prevent web scraping in two main ways: a field can be\n",
        "populated with a randomly generated variable on the form page that the server is\n",
        "expecting to be posted to the form-processing page. If this value is not present in the form, the server can reasonably assume that the submission did not originate organically from the form page, but was posted by a bot directly to the processing page. The\n",
        "best way to get around this measure is to scrape the form page first, collect the ran‐\n",
        "domly generated variable, and then post to the processing page from there.\n",
        "\n",
        "The second method is a “honeypot” of sorts. If a form contains a hidden field with an\n",
        "innocuous name, such as Username or Email Address, a poorly written bot might fill\n",
        "out the field and attempt to submit it, regardless of whether it is hidden to the users.\n",
        "Any hidden fields with actual values (or values that are different from their defaults\n",
        "on the form submission page) should be disregarded, and the user may even be\n",
        "blocked from the site."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYYDKnKTePL0",
        "colab_type": "text"
      },
      "source": [
        "##Avoiding Honeypots\n",
        "If a field on a web form is hidden from a user via CSS, it is reasonable to assume that the average user visiting the site will not be able to fill it out because it doesn’t show up in the browser.\n",
        "If the form is populated, there is likely a bot at work and the post will be discarded.\n",
        "\n",
        "A page visit to a “hidden” link on a site can easily trigger a server-side script that will block the user’s IP address, log that user out of the site, or take some other action to prevent further access. In fact, many business models have been based on exactly this concept.\n",
        "\n",
        "The example below uses the website *http://pythonscraping.com/pages/itsatrap.html*. This page contains two links, one hidden by CSS and another visible. It also contains a form with two hidden fields:\n",
        "\n",
        "```\n",
        "<html>\n",
        "<head>\n",
        "  <title>A bot-proof form</title>\n",
        "</head>\n",
        "<style>\n",
        "  body {\n",
        "    overflow-x:hidden;\n",
        "  }\n",
        "  .customHidden {\n",
        "    position:absolute;\n",
        "    right:50000px;\n",
        "  }\n",
        "</style>\n",
        "<body>\n",
        "  <h2>A bot-proof form</h2>\n",
        "  <a href=\n",
        "    \"http://pythonscraping.com/dontgohere\" style=\"display:none;\">Go here!</a>\n",
        "  <a href=\"http://pythonscraping.com\">Click me!</a>\n",
        "  <form>\n",
        "    <input type=\"hidden\" name=\"phone\" value=\"valueShouldNotBeModified\"/><p/>\n",
        "    <input type=\"text\" name=\"email\" class=\"customHidden\"\n",
        "      value=\"intentionallyBlank\"/><p/>\n",
        "    <input type=\"text\" name=\"firstName\"/><p/>\n",
        "    <input type=\"text\" name=\"lastName\"/><p/>\n",
        "    <input type=\"submit\" value=\"Submit\"/><p/>\n",
        "  </form>\n",
        "</body>\n",
        "</html>\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5FJXNDAfKui",
        "colab_type": "text"
      },
      "source": [
        "These three elements are hidden from the user in three ways:\n",
        "* The first link is hidden with a simple CSS `display:none` attribute.\n",
        "* The phone field is a hidden input field.\n",
        "* The email field is hidden by moving it 50,000 pixels to the right (presumably off\n",
        "the screen of everyone’s monitors) and hiding the telltale scroll bar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKPpEdukfVll",
        "colab_type": "text"
      },
      "source": [
        "The following code can retrieve the previously described page and looks for hidden links and form input fields:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFd2fWq4ffuv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.remote.webelement import WebElement"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_ld9_Mwfof3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "driver = webdriver.PhantomJS(executable_path='<Path to Phantom JS>')\n",
        "driver.get('http://pythonscraping.com/pages/itsatrap.html')\n",
        "links = driver.find_elements_by_tag_name('a')\n",
        "for link in links:\n",
        "  if not link.is_displayed():\n",
        "    print('The link {} is a trap'.format(link.get_attribute('href')))\n",
        "fields = driver.find_elements_by_tag_name('input')\n",
        "for field in fields:\n",
        "  if not field.is_displayed():\n",
        "    print('Do not change value of {}'.format(field.get_attribute('name')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggClcA_tgKoC",
        "colab_type": "text"
      },
      "source": [
        "It is dangerous to simply ignore hidden fields, although be careful when interacting with them."
      ]
    }
  ]
}