{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch1_preface_and_first_web_scraper.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lblogan14/web_scraping_with_python/blob/master/ch1_preface_and_first_web_scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yX8PYiEzU9MN",
        "colab_type": "text"
      },
      "source": [
        "To request the complete HTML code for *page1* located at the URL *http://pythonscraping.com/pages/page1.html.* just like what a web browser does, try the following three lines of codes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhHY9UatVeEr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from urllib.request import urlopen"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErC5PVSUVix8",
        "colab_type": "code",
        "outputId": "8bd51b1b-0f28-4eb8-f795-30c94bcb7fbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "html = urlopen('http://pythonscraping.com/pages/page1.html')\n",
        "print(html.read())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'<html>\\n<head>\\n<title>A Useful Page</title>\\n</head>\\n<body>\\n<h1>An Interesting Title</h1>\\n<div>\\nLorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\\n</div>\\n</body>\\n</html>\\n'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tZGJ-kiVv76",
        "colab_type": "text"
      },
      "source": [
        "This outputs the HTML file *page1.html*, found in the directory *\\<web root\\>/pages*, on the server located at the domain name *http://pythonscraping.com*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECtk2yRFWS6h",
        "colab_type": "text"
      },
      "source": [
        "*urllib* is a standard Python library and contains functions for requesting data across the web, handling cookies, and changing metadata such as headers and user agent. \\\\\n",
        "`ulropen` is used to open a remote object across a network and read it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpktHc0yWs6S",
        "colab_type": "text"
      },
      "source": [
        "#An Introduction to BeautifulSoup\n",
        "The *BeautifulSoup* library helps format and orgainze the messy web by fixing bad HTML and presenting with easily traversable Python objects representing XML structures."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkQ7J8ByXCin",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "##Installing BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74-JfYPnXBEy",
        "colab_type": "code",
        "outputId": "32f52c1a-4601-4169-9e88-afa5fa34ef0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip3 install beautifulsoup4"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (4.6.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97XELMqyXgB4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test installation of BeautifulSoup4\n",
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KP_13dbXuFT",
        "colab_type": "text"
      },
      "source": [
        "##Running BeautifulSoup\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pzhaj88mX4Kv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnlhtYiEX7U2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "html = urlopen('http://www.pythonscraping.com/pages/page1.html')\n",
        "bs = BeautifulSoup(html.read(), 'html.parser')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONf1W0gZcCRo",
        "colab_type": "text"
      },
      "source": [
        "The `BeautifulSoup` object requires two arguments: The first is the HTML text the object is based on, and the second specifies the parser\n",
        "that you want BeautifulSoup to use in order to create that object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96SPxSDmcBPJ",
        "colab_type": "code",
        "outputId": "a2ff4e97-f62b-4fdd-99f4-76275bb07994",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(bs.h1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<h1>An Interesting Title</h1>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWScQEj4YOIi",
        "colab_type": "text"
      },
      "source": [
        "This returns only the first instance of the `h1` tag found on the page, not necessarily the whole paragraph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "m6JXb695af2A"
      },
      "source": [
        "BeautifulSoup needs to call `html.read()` method first in order to get the HTML content of the page, unlike what the book said that without calling `.read()` method. Otherwise, an error shows up."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liwQHKR4YGeb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bs2 = BeautifulSoup(html, 'html.parser')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkP8HM1gZzcK",
        "colab_type": "text"
      },
      "source": [
        "This HTML content is transformed into a `BeautifulSoup` object, with the following structure:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyIBmd-vZFty",
        "colab_type": "code",
        "outputId": "b5d83dc5-f664-4c78-a15c-b7c1d9a1986b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(bs2.h1) # nothing shows up"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1y7AmCaMYw6U",
        "colab_type": "text"
      },
      "source": [
        "The HTML content is transformed into a `BeautifulSoup` object, with the following structure:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZ8Hm22ybXM6",
        "colab_type": "code",
        "outputId": "3fdc7171-589a-4b43-af75-7f8f62dc9043",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "print(bs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<html>\n",
            "<head>\n",
            "<title>A Useful Page</title>\n",
            "</head>\n",
            "<body>\n",
            "<h1>An Interesting Title</h1>\n",
            "<div>\n",
            "Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n",
            "</div>\n",
            "</body>\n",
            "</html>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6JHH2zHbbJq",
        "colab_type": "text"
      },
      "source": [
        "All of the following functions calls would produce the same output, even though the `h1` tag is nested two layers deep into the `BeautifulSoup` object structure (`html` $\\rightarrow$ 'body' $\\rightarrow$ 'h1'):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xoa0KkRWZ9x8",
        "colab_type": "code",
        "outputId": "bb8fe67e-3eee-42b2-8029-91011563a8f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(bs.h1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<h1>An Interesting Title</h1>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDgZjdKAZRYS",
        "colab_type": "code",
        "outputId": "81ca47ac-9abe-47e1-f4b2-003bd61bbc55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(bs.html.body.h1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<h1>An Interesting Title</h1>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9KQ4Wo0byGs",
        "colab_type": "code",
        "outputId": "9304a49b-7ad1-43b7-8ca1-348736695ad0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(bs.body.h1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<h1>An Interesting Title</h1>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-lFtk__b0JL",
        "colab_type": "code",
        "outputId": "3af46848-e225-45cc-e8f3-ec50b601d61d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(bs.html.h1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<h1>An Interesting Title</h1>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mO3HA7_ecZCA",
        "colab_type": "text"
      },
      "source": [
        "`html.parser` is a parser that is included with Python 3. Another popular parser is `lxml`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKnNQoGscj9E",
        "colab_type": "code",
        "outputId": "5f5b7caf-0c5f-4d46-e7bb-31282eb5e694",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip3 install lxml"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (4.2.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqSzi7I5coO3",
        "colab_type": "text"
      },
      "source": [
        "`lxml` can be used with BeautifulSoup by changing the parser string provided:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfMf-fRxcuw1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bs = BeautifulSoup(html.read(), 'lxml')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hyvtk_85dFaN",
        "colab_type": "text"
      },
      "source": [
        "lxml has some advantages over html.parser in that it is generally better at parsing\n",
        "“messy” or malformed HTML code. It is forgiving and fixes problems like unclosed\n",
        "tags, tags that are improperly nested, and missing head or body tags."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZkK9nlPdKeU",
        "colab_type": "text"
      },
      "source": [
        "Another popular HTML parser is `html5lib`, which is an extremely forgiving parser that takes even more initiative correcting broken HTML."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxSHa1dbdXPr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bs = BeautifulSoup(html.read(), 'html5lib')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGFNOR5QddS4",
        "colab_type": "text"
      },
      "source": [
        "##Connecting Reliably and Handling Exceptions\n",
        "There could be two things going wrong when scraping HTML data:\n",
        "1. The page is not found on the serveer (or there was an error in retrieving it)\n",
        "2. The server is not found"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyP0_50sd9wz",
        "colab_type": "text"
      },
      "source": [
        "The first situation can be handled in the following exception:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4w-7POXfeESP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from urllib.request import urlopen\n",
        "from urllib.error import HTTPError"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtRjoGU7eJp8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  html = urlopen('http://www.pythonscraping.com/pages/page1.html')\n",
        "except HTTPError as e:\n",
        "  print(e)\n",
        "  # return null, break, or do some other \"Plan B\"\n",
        "else:\n",
        "  # program continues. Note: If you return or break in the exception catch, you do not need to use the \"else\" statement"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdD1u7GAelOH",
        "colab_type": "text"
      },
      "source": [
        "If an HTTP error code is returned, the program now prints the error, and does not\n",
        "execute the rest of the program under the `else` statement."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9sbgYKoepKF",
        "colab_type": "text"
      },
      "source": [
        "In the second situation (where the HTML is down or the URL is mistyped), `urlopen` will throw an `URLError`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqFnRXWpe1gY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from urllib.request import urlopen\n",
        "from urllib.error import HTTPError\n",
        "from urllib.error import URLError"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMf_9Zwce3f7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  html = urlopen('https://pythonscrapingthisurldoesnotexist.com')\n",
        "except HTTPError as e:\n",
        "  print(e)\n",
        "except URLError as e:\n",
        "  print('The server could not be found!')\n",
        "else:\n",
        "  print('It Worked!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTg77N73fIM3",
        "colab_type": "text"
      },
      "source": [
        "When a nonexisting tag is accessed, BeautifulSoup will return a `None` object. Attempting to access a tag on a `None` object itself will result in a `AttributeError` being thrown:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jr5-AfYSfcrn",
        "colab_type": "code",
        "outputId": "aa7e5b0e-34f4-4b45-ae9e-821748c60528",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "print(bs.fakeTag)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/bs4/element.py:1110: UserWarning: .fakeTag is deprecated, use .find(\"fake\") instead. If you really were looking for a tag called fakeTag, use .find(\"fakeTag\")\n",
            "  name=tag_name\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0H7D5D3mfrCR",
        "colab_type": "text"
      },
      "source": [
        "The issue comes if another function is called on the `None` object:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_hpL8CEfwBM",
        "colab_type": "code",
        "outputId": "542bf385-49fc-4ba2-b16b-95b065a2ac1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "print(bs.fakeTag.someTag)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/bs4/element.py:1110: UserWarning: .fakeTag is deprecated, use .find(\"fake\") instead. If you really were looking for a tag called fakeTag, use .find(\"fakeTag\")\n",
            "  name=tag_name\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-bb2cf1f72f62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfakeTag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msomeTag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'someTag'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAl9B2_of5Ne",
        "colab_type": "text"
      },
      "source": [
        "To handle these situations both, try to check the following:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cu5fqzrSf9i-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  badContent = bs.nonExistingTag.anotherTag\n",
        "except AttributeError as e:\n",
        "  print('Tag was not found')\n",
        "else:\n",
        "  if badContent == None:\n",
        "    print('Tag was not found')\n",
        "  else:\n",
        "    print(badContent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWg1IjLigYUL",
        "colab_type": "text"
      },
      "source": [
        "To reorganize for easy reading and better integration:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lxpt52Fqgb6g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from urllib.request import urlopen\n",
        "from urllib.error import HTTPError\n",
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnDHDZ-BgdtC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getTitle(url):\n",
        "  try:\n",
        "    html = urlopen(url)\n",
        "  except HTTPError as e:\n",
        "    return None\n",
        "  \n",
        "  try:\n",
        "    bs = BeautifulSoup(html.read(), 'html.parser')\n",
        "    title = bs.body.h1\n",
        "  except AttributeError as e:\n",
        "    return None\n",
        "  return title"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VywQ0lJEg0mF",
        "colab_type": "code",
        "outputId": "4d66cbad-3623-43cc-c38f-95c60e7a50ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "title = getTitle('http://www.pythonscraping.com/pages/page1.html')\n",
        "if title == None:\n",
        "  print('Title could not be found')\n",
        "else:\n",
        "  print(title)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<h1>An Interesting Title</h1>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZluN0t_g_xh",
        "colab_type": "text"
      },
      "source": [
        "The function `getTitle` returns either the title of the page or a `None` object if there was a problem retrieving it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HbbrIMVhLfW",
        "colab_type": "text"
      },
      "source": [
        "When writing scrapers. it is important to think about the overall pattern of the code in order to handle exceptions and make it readable at the same time. Also having more generic functions such as `getSiteHTML` and `getTitle` to reuse code and make web scraping easily and quickly."
      ]
    }
  ]
}